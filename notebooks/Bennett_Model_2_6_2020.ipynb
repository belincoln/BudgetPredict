{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store -r df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tells matplotlib to embed plots within the notebook\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belincoln\\repos\\BudgetPredict\\data\n"
     ]
    }
   ],
   "source": [
    "os.chdir('C:\\\\Users\\\\belincoln\\\\repos\\\\BudgetPredict')\n",
    "# Set working directory to the data folder so you can correctly read in the csv files\n",
    "%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from DHS Contracts\n",
    "df = pd.read_csv('FY2019_070_Contracts_Full_20200110_1.csv', header = 0, usecols = ['contract_transaction_unique_key', \n",
    "                        'federal_action_obligation','total_dollars_obligated', 'base_and_exercised_options_value', \n",
    "                        'current_total_value_of_award', 'base_and_all_options_value','potential_total_value_of_award'],\n",
    "                 dtype = {'contract_transaction_unique_key':'str','federal_action_obligation': 'float',\n",
    "                        'total_dollars_obligated': 'float', 'base_and_exercised_options_value': 'float', \n",
    "                        'current_total_value_of_award': 'float', 'base_and_all_options_value': 'float',\n",
    "                        'potential_total_value_of_award': 'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 new features for analysis\n",
    "df['Percent awarded over potential total awarded'] = df['current_total_value_of_award'] / df['potential_total_value_of_award']\n",
    "df['Percent Cumulatively Obligated over potential total value of award'] = df['total_dollars_obligated'] / df['potential_total_value_of_award']\n",
    "df['Percent Cumulatively Obligated over total value already awarded'] = df['total_dollars_obligated'] / df['current_total_value_of_award']\n",
    "\n",
    "# Create Indicator Variable\n",
    "df['Indicator'] = df['federal_action_obligation']<-1000\n",
    "\n",
    "# set index to each transaction key\n",
    "df.set_index('contract_transaction_unique_key', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('federal_action_obligation', axis =1, inplace = True)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning of Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_dollars_obligated', 'base_and_exercised_options_value',\n",
       "       'current_total_value_of_award', 'base_and_all_options_value',\n",
       "       'potential_total_value_of_award',\n",
       "       'Percent awarded over potential total awarded',\n",
       "       'Percent Cumulatively Obligated over potential total value of award',\n",
       "       'Percent Cumulatively Obligated over total value already awarded',\n",
       "       'Indicator'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66533, 9)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_dollars_obligated                                               float64\n",
       "base_and_exercised_options_value                                      float64\n",
       "current_total_value_of_award                                          float64\n",
       "base_and_all_options_value                                            float64\n",
       "potential_total_value_of_award                                        float64\n",
       "Percent awarded over potential total awarded                          float64\n",
       "Percent Cumulatively Obligated over potential total value of award    float64\n",
       "Percent Cumulatively Obligated over total value already awarded       float64\n",
       "Indicator                                                                bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =  df.iloc[:,:-1], df.loc[:,'Indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_dollars_obligated                                               4.287900e+06\n",
      "base_and_exercised_options_value                                      2.652147e+05\n",
      "current_total_value_of_award                                          4.360394e+06\n",
      "base_and_all_options_value                                            2.585394e+06\n",
      "potential_total_value_of_award                                        2.365486e+07\n",
      "Percent awarded over potential total awarded                          8.497815e-01\n",
      "Percent Cumulatively Obligated over potential total value of award    8.404629e-01\n",
      "Percent Cumulatively Obligated over total value already awarded       9.223830e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def  featureNormalize(X):\n",
    "    \"\"\"\n",
    "    Normalizes the features in X. returns a normalized version of X where\n",
    "    the mean value of each feature is 0 and the standard deviation\n",
    "    is 1. This is often a good preprocessing step to do when working with\n",
    "    learning algorithms.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_norm : array_like\n",
    "        The normalized dataset of shape (m x n).\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    First, for each feature dimension, compute the mean of the feature\n",
    "    and subtract it from the dataset, storing the mean value in mu. \n",
    "    Next, compute the  standard deviation of each feature and divide\n",
    "    each feature by it's standard deviation, storing the standard deviation \n",
    "    in sigma. \n",
    "    \n",
    "    Note that X is a matrix where each column is a feature and each row is\n",
    "    an example. You needto perform the normalization separately for each feature. \n",
    "    \n",
    "    Hint\n",
    "    ----\n",
    "    You might find the 'np.mean' and 'np.std' functions useful.\n",
    "    \"\"\"\n",
    "    # You need to set these values correctly\n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    # =========================== YOUR CODE HERE =====================\n",
    "    mu = np.mean(X,axis=0)\n",
    "    sigma = np.std(X,axis=0)\n",
    "    X_norm = (X-mu)/sigma\n",
    "    # ================================================================\n",
    "    return X_norm, mu, sigma\n",
    "print(np.mean(X,axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm, mu, sigma = featureNormalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "\n",
    "#### Sigmoid function\n",
    "\n",
    "the logistic regression hypothesis is defined as:\n",
    "\n",
    "$$ h_\\theta(x) = g(\\theta^T x)$$\n",
    "\n",
    "where function $g$ is the sigmoid function. The sigmoid function is defined as: \n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$.\n",
    "\n",
    " For large positive values of `x`, the sigmoid should be close to 1, while for large negative values, the sigmoid should be close to 0. Evaluating `sigmoid(0)` should give you exactly 0.5. \n",
    " \n",
    " This is used for classification models (rather than regresssion models).\n",
    " \n",
    "<a id=\"sigmoid\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute sigmoid function given the input z.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : array_like\n",
    "        The input to the sigmoid function. This can be a 1-D vector \n",
    "        or a 2-D matrix. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    g : array_like\n",
    "        The computed sigmoid function. g has the same shape as z, since\n",
    "        the sigmoid is computed element-wise on z.\n",
    "        \n",
    "    Instructions\n",
    "    ------------\n",
    "    Compute the sigmoid of each value of z (z can be a matrix, vector or scalar).\n",
    "    \"\"\"\n",
    "    # convert input to a numpy array\n",
    "    z = np.array(z)\n",
    "    \n",
    "    # You need to return the following variables correctly \n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    temp = 1 + np.power(np.e,-z)\n",
    "    g = 1 / temp\n",
    "    \n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the data matrix appropriately, and add ones for the intercept term\n",
    "m, n = X.shape\n",
    "# Add intercept term to X\n",
    "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y to np.array of 0s and 1s\n",
    "y = np.array(y.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a function `costFunction` to return the cost and gradient. Recall that the cost function in logistic regression is\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ -y^{(i)} \\log\\left(h_\\theta\\left( x^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - h_\\theta\\left( x^{(i)} \\right) \\right) \\right]$$\n",
    "\n",
    "and the gradient (derivative) of the cost is a vector of the same length as $\\theta$ where the $j^{th}$\n",
    "element (for $j = 0, 1, \\cdots , n$) is defined as follows:\n",
    "\n",
    "$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} $$\n",
    "\n",
    "Note that while this gradient looks identical to the linear regression gradient, the formula is actually different because linear and logistic regression have different definitions of $h_\\theta(x)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(theta, X, y):\n",
    "    \"\"\"\n",
    "    Compute cost and gradient for logistic regression. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : array_like\n",
    "        The parameters for logistic regression. This a vector\n",
    "        of shape (n+1, ).\n",
    "    \n",
    "    X : array_like\n",
    "        The input dataset of shape (m x n+1) where m is the total number\n",
    "        of data points and n is the number of features. We assume the \n",
    "        intercept has already been added to the input.\n",
    "    \n",
    "    y : arra_like\n",
    "        Labels for the input. This is a vector of shape (m, ).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The computed value for the cost function. \n",
    "    \n",
    "    grad : array_like\n",
    "        A vector of shape (n+1, ) which is the gradient of the cost\n",
    "        function with respect to theta, at the current values of theta.\n",
    "        \n",
    "    Instructions\n",
    "    ------------\n",
    "    Compute the cost of a particular choice of theta. You should set J to \n",
    "    the cost. Compute the partial derivatives and set grad to the partial\n",
    "    derivatives of the cost w.r.t. each parameter in theta.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values\n",
    "    m = y.size  # number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "\n",
    "    h = sigmoid(np.dot(X,theta))\n",
    "    temp = -y*np.log(h) - (1-y)*np.log(1-h)\n",
    "    J = (1/m)*np.sum(temp)\n",
    "    grad = (1/m)*np.dot(X.T,(h-y))\n",
    "    # =============================================================\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6931471805599454\n",
      "Cost at initial theta (zeros):0.6931471805599454\n",
      "Gradient at initial theta (zeros):\n",
      "[ 0.4110216  -0.00184109  0.00936506 -0.00177696  0.00311307  0.00327162\n",
      "  0.00702852  0.0053589   0.0151578 ]\n",
      "Cost at test theta: nan\n",
      "Gradient at test theta: [-0.08588547  0.03642699  0.01514494  0.03641646  0.0297934   0.03406495\n",
      "  0.00388522  0.00236244  0.01139037]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belincoln\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\belincoln\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "# Initialize fitting parameters\n",
    "initial_theta = np.zeros(n+1)\n",
    "print(initial_theta)\n",
    "cost, grad = costFunction(initial_theta, X, y)\n",
    "print(cost)\n",
    "\n",
    "print('Cost at initial theta (zeros):' + str(cost))\n",
    "\n",
    "\n",
    "print('Gradient at initial theta (zeros):')\n",
    "print(grad)\n",
    "\n",
    "\n",
    "# Compute and display cost and gradient with non-zero theta\n",
    "test_theta = np.array([-24, 0.2, 0.2,3,4,5,6,7,8])\n",
    "cost, grad = costFunction(test_theta, X, y)\n",
    "\n",
    "print('Cost at test theta: {:.3f}'.format(cost))\n",
    "\n",
    "\n",
    "print('Gradient at test theta: ' + str(grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belincoln\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: overflow encountered in power\n",
      "C:\\Users\\belincoln\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\belincoln\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at theta found by optimize.minimize: 0.2983502743615043\n",
      "theta:\n",
      "[-2.18734618  0.01533018 -0.15916793  0.01424393 -0.04214222 -0.05694922\n",
      " -0.02841107  0.01745807 -0.15920108]\n"
     ]
    }
   ],
   "source": [
    "# set options for optimize.minimize\n",
    "options= {'maxiter': 400}\n",
    "\n",
    "# see documention for scipy's optimize.minimize  for description about\n",
    "# the different parameters\n",
    "# The function returns an object `OptimizeResult`\n",
    "# We use truncated Newton algorithm for optimization which is \n",
    "# equivalent to MATLAB's fminunc\n",
    "# See https://stackoverflow.com/questions/18801002/fminunc-alternate-in-numpy\n",
    "res = optimize.minimize(costFunction,\n",
    "                        initial_theta,\n",
    "                        (X, y),\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "\n",
    "# the fun property of `OptimizeResult` object returns\n",
    "# the value of costFunction at optimized theta\n",
    "cost = res.fun\n",
    "\n",
    "# the optimized theta is in the x property\n",
    "theta = res.x\n",
    "\n",
    "# Print theta to screen\n",
    "print('Cost at theta found by optimize.minimize: ' + str(cost))\n",
    "\n",
    "\n",
    "print('theta:')\n",
    "print(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfeatures = len(df.columns) - 2\\nfor i in range(features):\\n    fig = pyplot.figure()\\n    mask  = y == 1\\n    pyplot.plot(X[mask].iloc[:,i], X[mask].iloc[:, i+1], 'k*', lw=2, ms=10)\\n    pyplot.plot(X[~mask].iloc[:, i], X[~mask].iloc[:, i+1], 'ko', mfc='y', ms=8, mec='k', mew=1)\\n   \\n    # add axes labels\\n    pyplot.xlabel(df.columns[i])\\n    pyplot.ylabel(df.columns[i+1])\\n    pyplot.legend(['Sweep', 'Not a Sweep'])\\n    pass\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This produces a scatter plot with each of the features, \n",
    "# but does not cover each permutation of features\n",
    "# 10 min runtime, I should rethink this\n",
    "\n",
    "'''\n",
    "features = len(df.columns) - 2\n",
    "for i in range(features):\n",
    "    fig = pyplot.figure()\n",
    "    mask  = y == 1\n",
    "    pyplot.plot(X[mask].iloc[:,i], X[mask].iloc[:, i+1], 'k*', lw=2, ms=10)\n",
    "    pyplot.plot(X[~mask].iloc[:, i], X[~mask].iloc[:, i+1], 'ko', mfc='y', ms=8, mec='k', mew=1)\n",
    "   \n",
    "    # add axes labels\n",
    "    pyplot.xlabel(df.columns[i])\n",
    "    pyplot.ylabel(df.columns[i+1])\n",
    "    pyplot.legend(['Sweep', 'Not a Sweep'])\n",
    "    pass\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
